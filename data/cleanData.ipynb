{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação dos Datasets\n",
    "\n",
    "Aqui trataremos de:\n",
    "\n",
    "- Selecionar os datasets com os quais trabalharemos\n",
    "\n",
    "- Limpar dados\n",
    "\n",
    "- Reduzir a dimensionalidade dos dados para um espaço 2D (se necessário)\n",
    "\n",
    "- Reduzir a quantidade de rótulos dos nossos datasets para 2 rótulos (se necessário)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação das Funções de Limpeza, Redução e Plotagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, vamos criar as funções que usaremos para limpar os dados, reduzir eles para 2 dimensões e plotar eles de acordo com seus rótulos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que importamos todos os nossos datasets, vamos criar uma função que faz a limpeza dos dados, que consistirá apenas em:\n",
    "\n",
    "- Eliminar dados duplicados\n",
    "- Eliminar dados null/None/NaN\n",
    "\n",
    "OBS.: como veremos mais a frente, alguns dos nossos datasets precisarão de mais trabalho para limpeza, essa será apenas uma função de limpeza mais simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def cleanData(data):\n",
    "\n",
    "    dataframe = pd.DataFrame(data=data.data, columns=data.feature_names)\n",
    "    dataframe['target'] = data.target\n",
    "\n",
    "    dataframe = dataframe.dropna()\n",
    "    dataframe = dataframe.drop_duplicates()\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos essa função mais a frente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redução de Dimensão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que importamos e limpamos todos os nossos datasets, vamos criar uma função que faz a redução de dimensionalidade dos dados para 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def reduce2DPCA(df):\n",
    "    # Assuming last column is 'label'\n",
    "    features = df.iloc[:, :-1]\n",
    "    labels = df.iloc[:, -1]\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_features = pca.fit_transform(features)\n",
    "    \n",
    "    reduced_df = pd.DataFrame(reduced_features, columns=['x', 'y'])\n",
    "    reduced_df['label'] = labels.reset_index(drop=True)\n",
    "    \n",
    "    return reduced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos essa função mais a frente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que importamos, limpamos e reduzimos para 2D todos os nossos datasets, vamos criar uma função que faz a plota os nossos dados com cores diferentes para cada rótulo para podermos identificar quais são linearmente separáveis dos outros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotData(df, title):\n",
    "\n",
    "    if not {'x', 'y', 'label'}.issubset(df.columns):\n",
    "        print(\"DataFrame must contain 'x', 'y', and 'label' columns.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    uniqueLabels = df['label'].unique()\n",
    "    for label in uniqueLabels:\n",
    "        subset = df[df['label'] == label]\n",
    "        plt.scatter(subset['x'], subset['y'], label=label)\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos usar essa última função para plotar os nossos dados e verificar visualmente quais rotulos são linearmente separáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntando essas funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntando as funções que:\n",
    "\n",
    "- Faz a limpeza dos dados\n",
    "- Reduz os dados para 2D\n",
    "- Plota dos dados\n",
    "\n",
    "Temos a seguinte função:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanReducePlotData(data, title):\n",
    "    \n",
    "    plotData(reduce2DPCA(cleanData(data)), title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção e Limpeza dos Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vamos selecionar e importar os datasets que usaremos para esse trabalho.\n",
    "\n",
    "Usaremos dados de diferentes fontes para aplicar nosso modelo a diversas situações e ver seu desempenho mediante os diferentes desafios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os primeiros datasets que utilizaremos estarão contidos no scikit learn: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Iris Plants\n",
    "\n",
    "    Para mais informações, acesse:\n",
    "\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 149 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  149 non-null    float64\n",
      " 1   sepal width (cm)   149 non-null    float64\n",
      " 2   petal length (cm)  149 non-null    float64\n",
      " 3   petal width (cm)   149 non-null    float64\n",
      " 4   target             149 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 7.0 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "irisData = load_iris()\n",
    "\n",
    "irisDataframe = cleanData(irisData)\n",
    "\n",
    "irisDataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forest Covertypes\n",
    "\n",
    "    Para mais informações, acesse:\n",
    "\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html#sklearn.datasets.fetch_covtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 581012 entries, 0 to 581011\n",
      "Data columns (total 55 columns):\n",
      " #   Column                              Non-Null Count   Dtype  \n",
      "---  ------                              --------------   -----  \n",
      " 0   Elevation                           581012 non-null  float64\n",
      " 1   Aspect                              581012 non-null  float64\n",
      " 2   Slope                               581012 non-null  float64\n",
      " 3   Horizontal_Distance_To_Hydrology    581012 non-null  float64\n",
      " 4   Vertical_Distance_To_Hydrology      581012 non-null  float64\n",
      " 5   Horizontal_Distance_To_Roadways     581012 non-null  float64\n",
      " 6   Hillshade_9am                       581012 non-null  float64\n",
      " 7   Hillshade_Noon                      581012 non-null  float64\n",
      " 8   Hillshade_3pm                       581012 non-null  float64\n",
      " 9   Horizontal_Distance_To_Fire_Points  581012 non-null  float64\n",
      " 10  Wilderness_Area_0                   581012 non-null  float64\n",
      " 11  Wilderness_Area_1                   581012 non-null  float64\n",
      " 12  Wilderness_Area_2                   581012 non-null  float64\n",
      " 13  Wilderness_Area_3                   581012 non-null  float64\n",
      " 14  Soil_Type_0                         581012 non-null  float64\n",
      " 15  Soil_Type_1                         581012 non-null  float64\n",
      " 16  Soil_Type_2                         581012 non-null  float64\n",
      " 17  Soil_Type_3                         581012 non-null  float64\n",
      " 18  Soil_Type_4                         581012 non-null  float64\n",
      " 19  Soil_Type_5                         581012 non-null  float64\n",
      " 20  Soil_Type_6                         581012 non-null  float64\n",
      " 21  Soil_Type_7                         581012 non-null  float64\n",
      " 22  Soil_Type_8                         581012 non-null  float64\n",
      " 23  Soil_Type_9                         581012 non-null  float64\n",
      " 24  Soil_Type_10                        581012 non-null  float64\n",
      " 25  Soil_Type_11                        581012 non-null  float64\n",
      " 26  Soil_Type_12                        581012 non-null  float64\n",
      " 27  Soil_Type_13                        581012 non-null  float64\n",
      " 28  Soil_Type_14                        581012 non-null  float64\n",
      " 29  Soil_Type_15                        581012 non-null  float64\n",
      " 30  Soil_Type_16                        581012 non-null  float64\n",
      " 31  Soil_Type_17                        581012 non-null  float64\n",
      " 32  Soil_Type_18                        581012 non-null  float64\n",
      " 33  Soil_Type_19                        581012 non-null  float64\n",
      " 34  Soil_Type_20                        581012 non-null  float64\n",
      " 35  Soil_Type_21                        581012 non-null  float64\n",
      " 36  Soil_Type_22                        581012 non-null  float64\n",
      " 37  Soil_Type_23                        581012 non-null  float64\n",
      " 38  Soil_Type_24                        581012 non-null  float64\n",
      " 39  Soil_Type_25                        581012 non-null  float64\n",
      " 40  Soil_Type_26                        581012 non-null  float64\n",
      " 41  Soil_Type_27                        581012 non-null  float64\n",
      " 42  Soil_Type_28                        581012 non-null  float64\n",
      " 43  Soil_Type_29                        581012 non-null  float64\n",
      " 44  Soil_Type_30                        581012 non-null  float64\n",
      " 45  Soil_Type_31                        581012 non-null  float64\n",
      " 46  Soil_Type_32                        581012 non-null  float64\n",
      " 47  Soil_Type_33                        581012 non-null  float64\n",
      " 48  Soil_Type_34                        581012 non-null  float64\n",
      " 49  Soil_Type_35                        581012 non-null  float64\n",
      " 50  Soil_Type_36                        581012 non-null  float64\n",
      " 51  Soil_Type_37                        581012 non-null  float64\n",
      " 52  Soil_Type_38                        581012 non-null  float64\n",
      " 53  Soil_Type_39                        581012 non-null  float64\n",
      " 54  target                              581012 non-null  int32  \n",
      "dtypes: float64(54), int32(1)\n",
      "memory usage: 241.6 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "\n",
    "forestData = fetch_covtype()\n",
    "\n",
    "forestDataframe = irisDataframe = cleanData(forestData)\n",
    "\n",
    "forestDataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Wine Recognition\n",
    "\n",
    "    Para mais informações, acesse:\n",
    "\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   alcohol                       178 non-null    float64\n",
      " 1   malic_acid                    178 non-null    float64\n",
      " 2   ash                           178 non-null    float64\n",
      " 3   alcalinity_of_ash             178 non-null    float64\n",
      " 4   magnesium                     178 non-null    float64\n",
      " 5   total_phenols                 178 non-null    float64\n",
      " 6   flavanoids                    178 non-null    float64\n",
      " 7   nonflavanoid_phenols          178 non-null    float64\n",
      " 8   proanthocyanins               178 non-null    float64\n",
      " 9   color_intensity               178 non-null    float64\n",
      " 10  hue                           178 non-null    float64\n",
      " 11  od280/od315_of_diluted_wines  178 non-null    float64\n",
      " 12  proline                       178 non-null    float64\n",
      " 13  target                        178 non-null    int64  \n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 19.6 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wineData = load_wine()\n",
    "\n",
    "wineDataframe = cleanData(wineData)\n",
    "\n",
    "wineDataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Optical Recognition of Handwritten Digits\n",
    "\n",
    "    Para mais informações, acesse:\n",
    "\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1797 entries, 0 to 1796\n",
      "Data columns (total 65 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pixel_0_0  1797 non-null   float64\n",
      " 1   pixel_0_1  1797 non-null   float64\n",
      " 2   pixel_0_2  1797 non-null   float64\n",
      " 3   pixel_0_3  1797 non-null   float64\n",
      " 4   pixel_0_4  1797 non-null   float64\n",
      " 5   pixel_0_5  1797 non-null   float64\n",
      " 6   pixel_0_6  1797 non-null   float64\n",
      " 7   pixel_0_7  1797 non-null   float64\n",
      " 8   pixel_1_0  1797 non-null   float64\n",
      " 9   pixel_1_1  1797 non-null   float64\n",
      " 10  pixel_1_2  1797 non-null   float64\n",
      " 11  pixel_1_3  1797 non-null   float64\n",
      " 12  pixel_1_4  1797 non-null   float64\n",
      " 13  pixel_1_5  1797 non-null   float64\n",
      " 14  pixel_1_6  1797 non-null   float64\n",
      " 15  pixel_1_7  1797 non-null   float64\n",
      " 16  pixel_2_0  1797 non-null   float64\n",
      " 17  pixel_2_1  1797 non-null   float64\n",
      " 18  pixel_2_2  1797 non-null   float64\n",
      " 19  pixel_2_3  1797 non-null   float64\n",
      " 20  pixel_2_4  1797 non-null   float64\n",
      " 21  pixel_2_5  1797 non-null   float64\n",
      " 22  pixel_2_6  1797 non-null   float64\n",
      " 23  pixel_2_7  1797 non-null   float64\n",
      " 24  pixel_3_0  1797 non-null   float64\n",
      " 25  pixel_3_1  1797 non-null   float64\n",
      " 26  pixel_3_2  1797 non-null   float64\n",
      " 27  pixel_3_3  1797 non-null   float64\n",
      " 28  pixel_3_4  1797 non-null   float64\n",
      " 29  pixel_3_5  1797 non-null   float64\n",
      " 30  pixel_3_6  1797 non-null   float64\n",
      " 31  pixel_3_7  1797 non-null   float64\n",
      " 32  pixel_4_0  1797 non-null   float64\n",
      " 33  pixel_4_1  1797 non-null   float64\n",
      " 34  pixel_4_2  1797 non-null   float64\n",
      " 35  pixel_4_3  1797 non-null   float64\n",
      " 36  pixel_4_4  1797 non-null   float64\n",
      " 37  pixel_4_5  1797 non-null   float64\n",
      " 38  pixel_4_6  1797 non-null   float64\n",
      " 39  pixel_4_7  1797 non-null   float64\n",
      " 40  pixel_5_0  1797 non-null   float64\n",
      " 41  pixel_5_1  1797 non-null   float64\n",
      " 42  pixel_5_2  1797 non-null   float64\n",
      " 43  pixel_5_3  1797 non-null   float64\n",
      " 44  pixel_5_4  1797 non-null   float64\n",
      " 45  pixel_5_5  1797 non-null   float64\n",
      " 46  pixel_5_6  1797 non-null   float64\n",
      " 47  pixel_5_7  1797 non-null   float64\n",
      " 48  pixel_6_0  1797 non-null   float64\n",
      " 49  pixel_6_1  1797 non-null   float64\n",
      " 50  pixel_6_2  1797 non-null   float64\n",
      " 51  pixel_6_3  1797 non-null   float64\n",
      " 52  pixel_6_4  1797 non-null   float64\n",
      " 53  pixel_6_5  1797 non-null   float64\n",
      " 54  pixel_6_6  1797 non-null   float64\n",
      " 55  pixel_6_7  1797 non-null   float64\n",
      " 56  pixel_7_0  1797 non-null   float64\n",
      " 57  pixel_7_1  1797 non-null   float64\n",
      " 58  pixel_7_2  1797 non-null   float64\n",
      " 59  pixel_7_3  1797 non-null   float64\n",
      " 60  pixel_7_4  1797 non-null   float64\n",
      " 61  pixel_7_5  1797 non-null   float64\n",
      " 62  pixel_7_6  1797 non-null   float64\n",
      " 63  pixel_7_7  1797 non-null   float64\n",
      " 64  target     1797 non-null   int64  \n",
      "dtypes: float64(64), int64(1)\n",
      "memory usage: 912.7 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digiData = load_digits()\n",
    "\n",
    "digiDataframe = cleanData(digiData)\n",
    "\n",
    "digiDataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Diabetes\n",
    "\n",
    "    Para mais informações, acesse:\n",
    "\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 442 entries, 0 to 441\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   age     442 non-null    float64\n",
      " 1   sex     442 non-null    float64\n",
      " 2   bmi     442 non-null    float64\n",
      " 3   bp      442 non-null    float64\n",
      " 4   s1      442 non-null    float64\n",
      " 5   s2      442 non-null    float64\n",
      " 6   s3      442 non-null    float64\n",
      " 7   s4      442 non-null    float64\n",
      " 8   s5      442 non-null    float64\n",
      " 9   s6      442 non-null    float64\n",
      " 10  target  442 non-null    float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 38.1 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabData = load_diabetes()\n",
    "\n",
    "diabDataframe = cleanData(diabData)\n",
    "\n",
    "diabDataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Breast Cancer Wisconsin (Diagnostic)\n",
    "\n",
    "    Para mais informações, acesse:\n",
    "\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  target                   569 non-null    int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancerData = load_breast_cancer()\n",
    "\n",
    "cancerDataframe = cleanData(cancerData)\n",
    "\n",
    "cancerDataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para variarmos as fontes dos nossos dados, os próximos 2 serão datasets obtidos do kaggle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most Streamed Spotify Songs 2023\n",
    "\n",
    "    Para mais informações, acesse:\n",
    "\n",
    "    https://www.kaggle.com/datasets/nelgiriyewithana/top-spotify-songs-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotifyDataframe = pd.read_csv('spotify-2023.csv', encoding='ISO-8859-1')\n",
    "\n",
    "spotifyDataframe = spotifyDataframe.dropna()\n",
    "spotifyDataframe = spotifyDataframe.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 748 entries, 0 to 952\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   artist_count          748 non-null    int64 \n",
      " 1   released_year         748 non-null    int64 \n",
      " 2   released_month        748 non-null    int64 \n",
      " 3   released_day          748 non-null    int64 \n",
      " 4   in_spotify_playlists  748 non-null    int64 \n",
      " 5   in_spotify_charts     748 non-null    int64 \n",
      " 6   streams               748 non-null    int64 \n",
      " 7   in_apple_playlists    748 non-null    int64 \n",
      " 8   in_apple_charts       748 non-null    int64 \n",
      " 9   in_deezer_playlists   748 non-null    int64 \n",
      " 10  in_deezer_charts      748 non-null    int64 \n",
      " 11  in_shazam_charts      748 non-null    int64 \n",
      " 12  bpm                   748 non-null    int64 \n",
      " 13  mode                  748 non-null    int64 \n",
      " 14  danceability_%        748 non-null    int64 \n",
      " 15  valence_%             748 non-null    int64 \n",
      " 16  energy_%              748 non-null    int64 \n",
      " 17  acousticness_%        748 non-null    int64 \n",
      " 18  instrumentalness_%    748 non-null    int64 \n",
      " 19  liveness_%            748 non-null    int64 \n",
      " 20  speechiness_%         748 non-null    int64 \n",
      " 21  target                748 non-null    object\n",
      "dtypes: int64(21), object(1)\n",
      "memory usage: 134.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Transform object columns that are \n",
    "# int-like (streams, in_deezer_playlists, \n",
    "# in_shazam_charts) into int columns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Function to attempt to convert to int, returning NaN if it fails\n",
    "def tryConvertInt(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "spotifyDataframe['streams'] = spotifyDataframe['streams'].apply(tryConvertInt)\n",
    "spotifyDataframe['in_deezer_playlists'] = spotifyDataframe['in_deezer_playlists'].apply(tryConvertInt)\n",
    "spotifyDataframe['in_shazam_charts'] = spotifyDataframe['in_shazam_charts'].apply(tryConvertInt)\n",
    "\n",
    "spotifyDataframe.dropna(subset=['streams', 'in_deezer_playlists', 'in_shazam_charts'], inplace=True)\n",
    "\n",
    "# Avoid NaN transforming dataframe to float\n",
    "spotifyDataframe['streams'] = spotifyDataframe['streams'].astype(int)\n",
    "spotifyDataframe['in_deezer_playlists'] = spotifyDataframe['in_deezer_playlists'].astype(int)\n",
    "spotifyDataframe['in_shazam_charts'] = spotifyDataframe['in_shazam_charts'].astype(int)\n",
    "\n",
    "\n",
    "# Map the binary column 'mode' to 0 and 1\n",
    "\n",
    "mode_mapping = {\n",
    "    'minor': 0,\n",
    "    'major': 1\n",
    "}\n",
    "\n",
    "spotifyDataframe['mode'] = spotifyDataframe['mode'].str.lower().map(mode_mapping)\n",
    "spotifyDataframe = spotifyDataframe.dropna(subset=['mode'])\n",
    "\n",
    "\n",
    "# Delete the track_name and artist(s)_name columns\n",
    "\n",
    "spotifyDataframe = spotifyDataframe.drop(columns=['track_name', 'artist(s)_name'])\n",
    "\n",
    "\n",
    "# Make the key column the last \n",
    "# column and rename it to target\n",
    "\n",
    "col_X = spotifyDataframe['key']\n",
    "spotifyDataframe.drop(columns=['key'], inplace=True)\n",
    "spotifyDataframe['target'] = col_X\n",
    "\n",
    "\n",
    "spotifyDataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mobile Price Classification\n",
    "\n",
    "    Para mais informações, acesse:\n",
    "\n",
    "    https://www.kaggle.com/datasets/iabhishekofficial/mobile-price-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   battery_power  2000 non-null   int64  \n",
      " 1   blue           2000 non-null   int64  \n",
      " 2   clock_speed    2000 non-null   float64\n",
      " 3   dual_sim       2000 non-null   int64  \n",
      " 4   fc             2000 non-null   int64  \n",
      " 5   four_g         2000 non-null   int64  \n",
      " 6   int_memory     2000 non-null   int64  \n",
      " 7   m_dep          2000 non-null   float64\n",
      " 8   mobile_wt      2000 non-null   int64  \n",
      " 9   n_cores        2000 non-null   int64  \n",
      " 10  pc             2000 non-null   int64  \n",
      " 11  px_height      2000 non-null   int64  \n",
      " 12  px_width       2000 non-null   int64  \n",
      " 13  ram            2000 non-null   int64  \n",
      " 14  sc_h           2000 non-null   int64  \n",
      " 15  sc_w           2000 non-null   int64  \n",
      " 16  talk_time      2000 non-null   int64  \n",
      " 17  three_g        2000 non-null   int64  \n",
      " 18  touch_screen   2000 non-null   int64  \n",
      " 19  wifi           2000 non-null   int64  \n",
      " 20  price_range    2000 non-null   int64  \n",
      "dtypes: float64(2), int64(19)\n",
      "memory usage: 328.3 KB\n"
     ]
    }
   ],
   "source": [
    "mobileDataframe = pd.read_csv('mobile.csv', encoding='ISO-8859-1')\n",
    "\n",
    "mobileDataframe = mobileDataframe.dropna()\n",
    "mobileDataframe = mobileDataframe.drop_duplicates()\n",
    "\n",
    "mobileDataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, usamos as funções make_classification e make_blob do scikit learn para gerarmos 2 datasets aleatórios seguindo certos parâmetros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   feature1  100 non-null    float64\n",
      " 1   feature2  100 non-null    float64\n",
      " 2   target    100 non-null    float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 2.5 KB\n"
     ]
    }
   ],
   "source": [
    "# make_blobs generated data:\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "feat, targ = make_blobs(n_features=2, centers=2)\n",
    "\n",
    "genBlobData = np.column_stack((feat, targ))\n",
    "\n",
    "genBlobDataframe = pd.DataFrame(genBlobData, columns=[\"feature1\", \"feature2\", \"target\"])\n",
    "\n",
    "genBlobDataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   feature1  100 non-null    float64\n",
      " 1   feature2  100 non-null    float64\n",
      " 2   target    100 non-null    float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 2.5 KB\n"
     ]
    }
   ],
   "source": [
    "# make classification generated data:\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "feat, targ = make_classification(n_features=2, n_redundant=0, n_informative=1, n_clusters_per_class=1)\n",
    "\n",
    "genClassData = np.column_stack((feat, targ))\n",
    "\n",
    "genClassDataframe = pd.DataFrame(genClassData, columns=[\"feature1\", \"feature2\", \"target\"])\n",
    "\n",
    "genClassDataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redução da Quantidade de Rótulos do Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos todos os nossos datasets em dataframes, vamos aplicar a função"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
