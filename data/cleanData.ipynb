{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparação dos Datasets\n",
    "\n",
    "Aqui trataremos de:\n",
    "\n",
    "- Selecionar os datasets com os quais trabalharemos\n",
    "\n",
    "- Limpar dados\n",
    "\n",
    "- Reduzir a dimensionalidade dos dados para um espaço 2D (se necessário)\n",
    "\n",
    "- Reduzir a quantidade de rótulos dos nossos datasets para 2 rótulos (se necessário)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criação das Funções de Limpeza, Redução e Plotagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, vamos criar as funções que usaremos para limpar os dados, reduzir eles para 2 dimensões e plotar eles de acordo com seus rótulos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que importamos todos os nossos datasets, vamos criar uma função que faz a limpeza dos dados, que consistirá apenas em:\n",
    "\n",
    "- Eliminar dados duplicados\n",
    "- Eliminar dados null/None/NaN\n",
    "- Tranformar os Dados em um Pandas Dataframe\n",
    "\n",
    "OBS.: como veremos mais a frente, alguns dos nossos datasets precisarão de mais trabalho para limpeza, essa será apenas uma função de limpeza mais simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def cleanData(data):\n",
    "    \n",
    "    dataframe = pd.DataFrame(data=data.data, columns=data.feature_names)\n",
    "    dataframe['target'] = data.target\n",
    "\n",
    "    dataframe = dataframe.dropna()\n",
    "    dataframe = dataframe.drop_duplicates()\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos essa função mais a frente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redução de Dimensão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que importamos e limpamos todos os nossos datasets, vamos criar uma função que faz a redução de dimensionalidade dos dados para 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def reduce2DPCA(df):\n",
    "    # Assuming last column is 'label'\n",
    "    features = df.iloc[:, :-1]\n",
    "    labels = df.iloc[:, -1]\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_features = pca.fit_transform(features)\n",
    "    \n",
    "    reduced_df = pd.DataFrame(reduced_features, columns=['x', 'y'])\n",
    "    reduced_df['label'] = labels.reset_index(drop=True)\n",
    "    \n",
    "    return reduced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos essa função mais a frente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que importamos, limpamos e reduzimos para 2D todos os nossos datasets, vamos criar uma função que faz a plota os nossos dados com cores diferentes para cada rótulo para podermos identificar quais são linearmente separáveis dos outros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotData(df, title):\n",
    "\n",
    "    if not {'x', 'y', 'label'}.issubset(df.columns):\n",
    "        print(\"DataFrame must contain 'x', 'y', and 'label' columns.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    uniqueLabels = df['label'].unique()\n",
    "    for label in uniqueLabels:\n",
    "        subset = df[df['label'] == label]\n",
    "        plt.scatter(subset['x'], subset['y'], label=label)\n",
    "\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos usar essa última função para plotar os nossos dados e verificar visualmente quais rotulos são linearmente separáveis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntando essas funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntando as funções que:\n",
    "\n",
    "- Faz a limpeza dos dados\n",
    "- Reduz os dados para 2D\n",
    "- Plota dos dados\n",
    "\n",
    "Temos a seguinte função:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanReducePlotData(data, title):\n",
    "    \n",
    "    plotData(reduce2DPCA(cleanData(data)), title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção dos Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vamos selecionar e importar os datasets que usaremos para esse trabalho.\n",
    "\n",
    "Usaremos dados de diferentes fontes para aplicar nosso modelo a diversas situações e ver seu desempenho mediante os diferentes desafios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os primeiros datasets que utilizaremos estarão contidos no scikit learn: \n",
    "\n",
    "- Iris Plants\n",
    "\n",
    "    Para mais informações, acesse:\n",
    "\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris\n",
    "\n",
    "- Forest Covertypes\n",
    "\n",
    "    Para mais informações, acesse:\n",
    "\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html#sklearn.datasets.fetch_covtype\n",
    "\n",
    "- Wine Recognition\n",
    "\n",
    "    Para mais informações, acesse:\n",
    "\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine\n",
    "\n",
    "- Optical Recognition of Handwritten Digits\n",
    "\n",
    "    Para mais informações, acesse:\n",
    "\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html#sklearn.datasets.load_digits\n",
    "\n",
    "- Diabetes\n",
    "\n",
    "    Para mais informações, acesse:\n",
    "\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html#sklearn.datasets.load_diabetes\n",
    "\n",
    "- Breast Cancer Wisconsin (Diagnostic)\n",
    "\n",
    "    Para mais informações, acesse:\n",
    "\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para variarmos as fontes dos nossos dados, os próximos 2 serão datasets obtidos do kaggle:\n",
    "\n",
    "- Most Streamed Spotify Songs 2023\n",
    "\n",
    "    Para mais informações, acesse:\n",
    "\n",
    "    https://www.kaggle.com/datasets/nelgiriyewithana/top-spotify-songs-2023\n",
    "\n",
    "- Mobile Price Classification\n",
    "\n",
    "    Para mais informações, acesse:\n",
    "\n",
    "    https://www.kaggle.com/datasets/iabhishekofficial/mobile-price-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, usamos as funções make_classification e make_blob do scikit learn para gerarmos 2 datasets aleatórios seguindo certos parâmetros. \n",
    "\n",
    "Dado isso, não anexaremos referências a esses datasets, porém sua implementação será visto mais a frente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
